# 游늳 Bitcoin Price Prediction using Machine Learning

> **Trabajo Pr치ctico - Machine Learning**

Este proyecto, realizado para la Materia Machine Learning, aborda el desaf칤o de predecir el precio futuro de Bitcoin en un horizonte de 7 d칤as. Se implement칩 un flujo de trabajo completo de Ciencia de Datos, desde la ingenier칤a de caracter칤sticas con indicadores t칠cnicos hasta la optimizaci칩n de hiperpar치metros y evaluaci칩n en datos no vistos (Test Set).

## Key Features

* **Ingenier칤a de Caracter칤sticas:** Generaci칩n de indicadores t칠cnicos (RSI, MACD, Bandas de Bollinger, ATR) y variables de lag utilizando `pandas-ta`.
* **An치lisis Exploratorio (EDA):** Estudio de correlaciones con mercados tradicionales (S&P 500, Nasdaq), estacionalidad semanal y an치lisis de sentimiento (Fear & Greed Index).
* **Modelos Implementados:**
    * **K-Nearest Neighbors (KNN):** Regresi칩n basada en instancias.
    * **Random Forest:** Ensemble learning con optimizaci칩n de profundidad y estimadores.
    * **Regresi칩n Ridge:** Modelo lineal con regularizaci칩n L2.
    * **Redes Neuronales (Deep Learning):** Arquitectura densa optimizada con **Keras Tuner**.
* **Metodolog칤a Rigurosa:** Separaci칩n estricta de datos en *Train* (Entrenamiento), *Validation* (Ajuste de Hiperpar치metros) y *Test* (Evaluaci칩n Final) respetando el orden temporal.

## Tech Stack
* **Lenguaje:** Python 3.13
* **Librer칤as Principales:**
    * `pandas` & `numpy`: Manipulaci칩n de datos.
    * `scikit-learn`: Modelado y preprocesamiento (Pipelines, ColumnTransformer).
    * `tensorflow` / `keras`: Redes Neuronales.
    * `keras-tuner`: B칰squeda de hiperpar치metros para la red neuronal.
    * `pandas_ta`: C치lculo de indicadores t칠cnicos financieros.
    * `yfinance`: Extracci칩n de datos hist칩ricos.
    * `matplotlib` & `seaborn`: Visualizaci칩n de datos.

## Estructura del Proyecto

El an치lisis se divide en notebooks espec칤ficos para cada etapa y modelo:

1.  `analisis_exploratorios`: Carga de datos, limpieza, c치lculo de indicadores y EDA.
2.  `modelo_RL`: Implementaci칩n y optimizaci칩n de Regresi칩n Lineal (Ridge).
3.  `modelo_KNN`: Implementaci칩n de KNN con escalado de variables.
4.  `modelo_Random_Forest`: Entrenamiento de Random Forest con b칰squeda de grilla (GridSearch).
5.  `modelo_RN`: Dise침o y tuning de Red Neuronal Artificial (ANN).

## Resultados y Metodolog칤a

Para garantizar una evaluaci칩n honesta, se utilizaron las siguientes m칠tricas sobre el conjunto de **Test** (datos nunca vistos por el modelo durante el ajuste):

* **RMSE (Root Mean Squared Error):** Para penalizar grandes errores.
* **MAPE (Mean Absolute Percentage Error):** Para interpretabilidad del error en porcentaje.

*Se observ칩 que los modelos de ensamble (Random Forest) y la Regresion Lineal obtuvieron los mejores resultados en distintos horizontes de tiempo, +1 dia para Regresion Lineal y +2 a +7 dias para Random Forest.*

---
